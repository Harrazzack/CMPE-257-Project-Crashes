# -*- coding: utf-8 -*-
"""ProjectExp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18XSYmjlLoYqWyVZBS55w6f1FazJ5xRd3
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# prompt: add the google drive datset files

# Load the datasets into pandas dataframes
dfc = pd.read_csv("./data/crashes.csv")
dfv = pd.read_csv('./data/vehicles.csv')

# Display the first few rows and info for initial inspection
print("Crashes Data Info:")
dfc_info = dfc.info()


print("Vehicles Data Info:")
# Display the first few rows and info for initial inspection
dfv_info = dfv.info()

import matplotlib.pyplot as plt
import seaborn as sns
import folium
import plotly.express as px

# First, clean the data by handling any missing values or necessary conversions

# Filling missing numerical columns with 0 and categorical with 'Unknown' for simplicity

dfc.fillna(0, inplace=True)

dfv.fillna(0, inplace=True)



"""# Basic EDA

### Severity Distribution
"""

# Renaming df1 to dfc and df2 to dfv in the code and re-running the visualizations

# Visualization 1: Accident Severity Distribution
injury_columns = ['FatalInjuries', 'SevereInjuries', 'ModerateInjuries', 'MinorInjuries']
injury_counts = dfc[injury_columns].sum()

plt.figure(figsize=(8, 6))
injury_counts.plot(kind='bar', color=['red', 'orange', 'yellow', 'green'])
plt.title('Accident Severity Distribution')
plt.ylabel('Number of Injuries')
plt.xlabel('Severity')
plt.xticks(rotation=45)
plt.show()

dfc.columns

import folium

# Set the sample size (ensure it's less than or equal to the total available rows)
sample_size = min(500, dfc.shape[0])  # Ensure we don't exceed the dataset size

# Create a folium map centered on San Jose
accident_map = folium.Map(location=[37.3382, -121.8863], zoom_start=12)

# Loop through the sampled data
for i in range(sample_size):
    lat, lon = dfc['Latitude'].iloc[i], dfc['Longitude'].iloc[i]

    # Ensure latitude and longitude are valid (not NaN)
    if pd.notna(lat) and pd.notna(lon):
        folium.CircleMarker([lat, lon], radius=2, color='red', fill=True).add_to(accident_map)

# Show the map
accident_map

from folium.plugins import HeatMap


# Group the data by Latitude and Longitude, and count the number of accidents at each location
# We assume dfc contains accident data with 'Latitude' and 'Longitude' columns.
location_accident_count = dfc.groupby(['Latitude', 'Longitude']).size().reset_index(name='count')

# Filter out rows where Latitude or Longitude are NaN
location_accident_count = location_accident_count.dropna(subset=['Latitude', 'Longitude'])

# Prepare the data for the heatmap (latitude, longitude, weight)
heat_data = [[row['Latitude'], row['Longitude'], row['count']] for index, row in location_accident_count.iterrows()]

# Create a folium map centered on San Jose
accident_map = folium.Map(location=[37.3382, -121.8863], zoom_start=12)

# Add the heatmap to the map
HeatMap(heat_data).add_to(accident_map)

# Show the map
accident_map


 # Group the data by Latitude and Longitude, and count the number of accidents at each location
location_accident_count = dfc.groupby(['Latitude', 'Longitude']).size().reset_index(name='count')

# Filter out rows where Latitude or Longitude are NaN
location_accident_count = location_accident_count.dropna(subset=['Latitude', 'Longitude'])

# Define risk categories based on the accident count thresholds
def classify_risk(count):
    if count >= 10:  # Define high risk as 10 or more accidents
        return 'high'
    elif count >= 5:  # Define medium risk as 5-9 accidents
        return 'medium'
    else:  # Define low risk as fewer than 5 accidents
        return 'low'

# Apply the risk classification
location_accident_count['risk'] = location_accident_count['count'].apply(classify_risk)

# Create a folium map centered on San Jose
accident_map = folium.Map(location=[37.3382, -121.8863], zoom_start=12)

# Function to choose color based on risk level
def get_color(risk):
    if risk == 'high':
        return 'red'
    elif risk == 'medium':
        return 'orange'
    else:
        return 'green'

# Add Circle Markers for each location based on the risk level
for _, row in location_accident_count.iterrows():
    lat, lon, risk = row['Latitude'], row['Longitude'], row['risk']
    folium.CircleMarker(
        location=[lat, lon],
        radius=6,
        color=get_color(risk),
        fill=True,
        fill_color=get_color(risk),
        fill_opacity=0.6,
        popup=f'Risk: {risk}, Accidents: {row["count"]}'
    ).add_to(accident_map)

# Show the map
accident_map



# Group the data by Latitude and Longitude, and count the number of accidents at each location
location_accident_count = dfc.groupby(['Latitude', 'Longitude']).size().reset_index(name='count')

# Filter out rows where Latitude or Longitude are NaN
location_accident_count = location_accident_count.dropna(subset=['Latitude', 'Longitude'])

# Define risk categories based on the accident count thresholds
def classify_risk(count):
    if count >= 10:  # Define high risk as 10 or more accidents
        return 'high'
    elif count >= 5:  # Define medium risk as 5-9 accidents
        return 'medium'
    else:  # Define low risk as fewer than 5 accidents
        return 'low'

# Apply the risk classification
location_accident_count['risk'] = location_accident_count['count'].apply(classify_risk)

# Filter out low-risk locations
filtered_data = location_accident_count[location_accident_count['risk'].isin(['medium', 'high'])]

# Create a folium map centered on San Jose
accident_map = folium.Map(location=[37.3382, -121.8863], zoom_start=12)

# Function to choose color based on risk level
def get_color(risk):
    if risk == 'high':
        return 'red'
    elif risk == 'medium':
        return 'orange'

# Add Circle Markers for medium and high-risk locations
for _, row in filtered_data.iterrows():
    lat, lon, risk = row['Latitude'], row['Longitude'], row['risk']
    folium.CircleMarker(
        location=[lat, lon],
        radius=6,
        color=get_color(risk),
        fill=True,
        fill_color=get_color(risk),
        fill_opacity=0.6,
        popup=f'Risk: {risk}, Accidents: {row["count"]}'
    ).add_to(accident_map)

# Show the map
accident_map




# Visualization 5: Top Crash Factors
plt.figure(figsize=(10, 6))
top_factors = dfv['ViolationCodeDescription'].value_counts().head(10)
top_factors.plot(kind='bar', color='purple')
plt.title('Top 10 Crash Factors')
plt.ylabel('Count')
plt.xlabel('Violation Code Description')
plt.xticks(rotation=45)
plt.show()

# Visualization 6: Accidents Involving Speeding
plt.figure(figsize=(6, 6))
speeding_flag = dfc['SpeedingFlag'].value_counts()
speeding_flag.plot(kind='pie', autopct='%1.1f%%', colors=['lightblue', 'orange'], startangle=90)
plt.title('Accidents Involving Speeding')
plt.ylabel('')
plt.show()

# Visualization 7: Crash Severity by Vehicle Count
plt.figure(figsize=(10, 6))
sns.barplot(x='VehicleCount', y='FatalInjuries', data=dfv, ci=None, palette='coolwarm')
plt.title('Crash Severity by Vehicle Count')
plt.ylabel('Fatal Injuries')
plt.xlabel('Vehicle Count')
plt.xticks(rotation=45)
plt.show()

# Visualization 8: Hit-and-Run Incidents
plt.figure(figsize=(6, 6))
hit_and_run = dfc['HitAndRunFlag'].value_counts()
hit_and_run.plot(kind='pie', autopct='%1.1f%%', colors=['lightgreen', 'red'], startangle=90)
plt.title('Hit-and-Run Incidents')
plt.ylabel('')
plt.show()

# Visualization 9: Injury Severity by Vehicle Make
plt.figure(figsize=(12, 6))
sns.boxplot(x='VehicleMakeModelType', y='FatalInjuries', data=dfv, showfliers=False)
plt.title('Injury Severity by Vehicle Make')
plt.ylabel('Fatal Injuries')
plt.xlabel('Vehicle Make')
plt.xticks(rotation=90)
plt.show()
